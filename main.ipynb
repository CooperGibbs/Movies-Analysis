{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "#PYSPARK_DRIVER_PYTHON = 3.85\n",
    "#PYSPARK_PYTHON = 3.85\n",
    "import os\n",
    "import sys\n",
    "#import pyspark as spark\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Same code as shown in SimpleApp.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_with_spark(log_file=\"data/movies.csv\", app_name=\"movieAnalysis\"):\n",
    "    spark = SparkSession.builder.config(\"spark.executor.memory\", \"2g\").config(\"spark.driver.memory\", \"2g\").config(\"spark.storage.memoryFraction\", \"0.6\").appName(app_name).getOrCreate()\n",
    "    df = spark.read.option(\"header\",True).csv(log_file).cache()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\"\"\"\n",
    "1. Summary statistics for each relevant data frame\n",
    "\n",
    "\"\"\"\n",
    "def summary_statistics(df: pyspark.sql.dataframe.DataFrame, cols= [\"*\"], stats = [\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"]):\n",
    "    df.select(*cols).summary(*stats).show()\n",
    "# 1. Do all\n",
    "def summary_statistics_complete(file= \"data/ratings.csv\", cols= [\"*\"], stats = [\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"]):\n",
    "    summary_statistics(open_with_spark(file), cols, stats)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "2. Join Dataframes READABLE version, more memory needed\n",
    "\n",
    "\"\"\"\n",
    "def join_ratings_and_movies_readable():  \n",
    "    df_movie = open_with_spark()\n",
    "    df_ratings = open_with_spark(log_file=\"data/ratings.csv\", app_name=\"ratings\")\n",
    "    df_join = df_ratings.join(df_movie, \"movieID\")\n",
    "    return df_join\n",
    "    \n",
    "# 2. Join Dataframes\n",
    "def join_ratings_and_movies(): \n",
    "    return open_with_spark().join(open_with_spark(log_file=\"data/ratings.csv\", app_name=\"ratings\"), \"movieID\")\n",
    "\n",
    "\"\"\"\n",
    "3. Most-rated movies\n",
    "\n",
    "Returns the top N movies with the most reviews (ratings)\n",
    "\n",
    "\"\"\"\n",
    "# 3. Most-rated movies\n",
    "def most_rated(df: pyspark.sql.dataframe.DataFrame, N=10):\n",
    "    return df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False).limit(N)\n",
    "\n",
    "# 3. Function that does everything; can be used for timing or outputting or whatever\n",
    "def most_rated_complete(N=10):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = most_rated(JOINED, N)\n",
    "    return TOP_N\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "4. Highest-average-rated movies\n",
    "\n",
    "Returns the top N movies with the highest average reviews (ratings)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 4. Highest-average-rated movies\n",
    "def best_average_rated(df: pyspark.sql.dataframe.DataFrame, N=10, MIN_RATINGS=50):\n",
    "    T = df.groupby(\"title\").agg(F.mean(\"rating\"))\n",
    "    H = T.withColumnRenamed(\"avg(rating)\", \"Mean_rating\")\n",
    "    # H.show(5)\n",
    "    G = df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\")\n",
    "    C = H.join(G, \"title\")\n",
    "    C = C.filter(C.Num_ratings >= MIN_RATINGS).select([\"title\", \"Mean_rating\"])\n",
    "    J = C.sort(\"Mean_rating\", ascending=False)\n",
    "    K = J.limit(N).withColumn(\"Mean_rating\", F.round(\"Mean_rating\",3))\n",
    "    return K\n",
    "\n",
    "# 4. Function that does everything; can be used for timing or outputting or whatever\n",
    "def best_average_rated_complete(N=10, MIN_RATINGS=50):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = best_average_rated(JOINED, N, MIN_RATINGS)\n",
    "    return TOP_N \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "5. Popular genres: \n",
    "\n",
    "Find the top N popular genres by calculating the average rating for each genre.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def popular_genres(df: pyspark.sql.dataframe.DataFrame, N=5, MIN_RATINGS=10):\n",
    "    L = df.groupby(\"genres\").agg(F.mean(\"rating\"))\n",
    "    L.show(5)\n",
    "    M = L.withColumnRenamed(\"avg(rating)\", \"Mean_rating\")\n",
    "    G = df.groupby(\"genres\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\")\n",
    "    M.show(5)\n",
    "    K = M.join(G, \"genres\")\n",
    "    P = K.filter(K.Num_ratings >= MIN_RATINGS).select([\"genres\", \"Mean_rating\"])\n",
    "    N = P.sort(\"Mean_rating\", ascending=False).limit(N).withColumn(\"Mean_rating\", F.round(\"Mean_rating\",3))\n",
    "    return N\n",
    "# 5. Retrives DF then computes Top N DF\n",
    "def popular_genres_complete(N=5, MIN_RATINGS=10):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = popular_genres(JOINED, N)\n",
    "    return TOP_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 17:53:18 WARN Utils: Your hostname, Anthonys-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.67.104.86 instead (on interface en0)\n",
      "23/04/18 17:53:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 17:53:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+-------+-----+\n",
      "|summary|title|\n",
      "+-------+-----+\n",
      "|  count|58098|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 17:53:34 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "23/04/18 17:53:34 WARN MemoryStore: Not enough space to cache rdd_35_5 in memory! (computed 54.7 MiB so far)\n",
      "23/04/18 17:53:34 WARN BlockManager: Persisting block rdd_35_5 to disk instead.\n",
      "23/04/18 17:53:34 WARN MemoryStore: Not enough space to cache rdd_35_1 in memory! (computed 54.3 MiB so far)\n",
      "23/04/18 17:53:34 WARN BlockManager: Persisting block rdd_35_1 to disk instead.\n",
      "23/04/18 17:53:34 WARN MemoryStore: Not enough space to cache rdd_35_7 in memory! (computed 54.6 MiB so far)\n",
      "23/04/18 17:53:34 WARN BlockManager: Persisting block rdd_35_7 to disk instead.\n",
      "23/04/18 17:53:34 WARN MemoryStore: Not enough space to cache rdd_35_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/18 17:53:34 WARN BlockManager: Persisting block rdd_35_3 to disk instead.\n",
      "23/04/18 17:53:34 WARN MemoryStore: Not enough space to cache rdd_35_6 in memory! (computed 54.7 MiB so far)\n",
      "23/04/18 17:53:34 WARN BlockManager: Persisting block rdd_35_6 to disk instead.\n",
      "23/04/18 17:53:34 WARN MemoryStore: Not enough space to cache rdd_35_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/18 17:53:34 WARN BlockManager: Persisting block rdd_35_4 to disk instead.\n",
      "23/04/18 17:53:37 WARN MemoryStore: Not enough space to cache rdd_35_6 in memory! (computed 22.6 MiB so far)\n",
      "23/04/18 17:53:37 WARN MemoryStore: Not enough space to cache rdd_35_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/18 17:53:37 WARN MemoryStore: Not enough space to cache rdd_35_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/18 17:53:37 WARN MemoryStore: Not enough space to cache rdd_35_1 in memory! (computed 6.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|summary|userID|\n",
      "+-------+------+\n",
      "|  count|283228|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Print out number of movies and number of unqiue users.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "summary_statistics_complete(\"data/movies.csv\",[\"title\"], [\"count\"])\n",
    "# Get df of unique users\n",
    "df_unique_users = open_with_spark(\"data/ratings.csv\").select(\"UserID\").distinct()\n",
    "summary_statistics(df_unique_users,[\"userID\"], [\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/17 14:41:22 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/17 14:41:22 WARN MemoryStore: Not enough space to cache rdd_35_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/17 14:41:22 WARN MemoryStore: Not enough space to cache rdd_35_2 in memory! (computed 35.2 MiB so far)\n",
      "23/04/17 14:41:22 WARN MemoryStore: Not enough space to cache rdd_35_1 in memory! (computed 35.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          27753444|\n",
      "|   mean|3.5304452124932677|\n",
      "| stddev| 1.066352750231989|\n",
      "|    min|               0.5|\n",
      "|    25%|               3.0|\n",
      "|    50%|               3.5|\n",
      "|    75%|               4.0|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "summary_statistics_complete(\"data/ratings.csv\",[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 17:33:23 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/18 17:33:23 WARN MemoryStore: Not enough space to cache rdd_35_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/18 17:33:23 WARN MemoryStore: Not enough space to cache rdd_35_1 in memory! (computed 35.3 MiB so far)\n",
      "23/04/18 17:33:23 WARN MemoryStore: Not enough space to cache rdd_35_6 in memory! (computed 35.4 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o79.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1._next(SparkPlan.scala:393)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.getNext(SparkPlan.scala:402)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.getNext(SparkPlan.scala:388)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.util.NextIterator.foreach(NextIterator.scala:21)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1$adapted(SparkPlan.scala:424)\n\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$3709/0x0000000801f66cf8.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3688)\n\tat org.apache.spark.sql.Dataset$$Lambda$3660/0x0000000801f2d168.apply(Unknown Source)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.Dataset$$Lambda$2086/0x0000000801b944f0.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset$$Lambda$1753/0x0000000801abd458.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1764/0x0000000801ac0d48.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1754/0x0000000801abd718.apply(Unknown Source)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3685)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000000801160400.invoke(LambdaForm$MH)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m R \u001b[39m=\u001b[39m open_with_spark(\u001b[39m\"\u001b[39m\u001b[39mdata/ratings.csv\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mhist(R\u001b[39m.\u001b[39;49mcollect())\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcollectToPython()\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    191\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o79.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1._next(SparkPlan.scala:393)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.getNext(SparkPlan.scala:402)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.getNext(SparkPlan.scala:388)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.util.NextIterator.foreach(NextIterator.scala:21)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollect$1$adapted(SparkPlan.scala:424)\n\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$3709/0x0000000801f66cf8.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3688)\n\tat org.apache.spark.sql.Dataset$$Lambda$3660/0x0000000801f2d168.apply(Unknown Source)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.Dataset$$Lambda$2086/0x0000000801b944f0.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset$$Lambda$1753/0x0000000801abd458.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1764/0x0000000801ac0d48.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.execution.SQLExecution$$$Lambda$1754/0x0000000801abd718.apply(Unknown Source)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3685)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000000801160400.invoke(LambdaForm$MH)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "R = open_with_spark(\"data/ratings.csv\").select(\"rating\")\n",
    "plt.hist(R.collect())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Join Dataframes READABLE version, more memory needed\n",
    "def join_ratings_and_movies_readable():  \n",
    "    df_movie = open_with_spark()\n",
    "    df_ratings = open_with_spark(log_file=\"data/ratings.csv\", app_name=\"ratings\")\n",
    "    df_join = df_ratings.join(df_movie, \"movieID\")\n",
    "    return df_join\n",
    "    \n",
    "# 2. Join Dataframes\n",
    "def join_ratings_and_movies(): \n",
    "    return open_with_spark().join(open_with_spark(log_file=\"data/ratings.csv\", app_name=\"ratings\"), \"movieID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 18:10:41 WARN Utils: Your hostname, Anthonys-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.67.104.86 instead (on interface en0)\n",
      "23/04/18 18:10:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 18:10:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/18 18:10:44 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+------+------+----------+\n",
      "|movieId|               title|        genres|userId|rating| timestamp|\n",
      "+-------+--------------------+--------------+------+------+----------+\n",
      "|    307|Three Colors: Blu...|         Drama|     1|   3.5|1256677221|\n",
      "|    481|   Kalifornia (1993)|Drama|Thriller|     1|   3.5|1256677456|\n",
      "|   1091|Weekend at Bernie...|        Comedy|     1|   1.5|1256677471|\n",
      "|   1257|Better Off Dead.....|Comedy|Romance|     1|   4.5|1256677460|\n",
      "|   1449|Waiting for Guffm...|        Comedy|     1|   4.5|1256677264|\n",
      "+-------+--------------------+--------------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 18:10:57 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "X = join_ratings_and_movies()\n",
    "X.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/13 17:40:44 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 35.3 MiB so far)\n",
      "23/04/13 17:40:44 WARN BlockManager: Persisting block rdd_32_1 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_7 in memory! (computed 54.6 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_7 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_2 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_6 in memory! (computed 54.7 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_6 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_4 to disk instead.\n",
      "23/04/13 17:40:51 WARN MemoryStore: Not enough space to cache rdd_32_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/13 17:40:51 WARN BlockManager: Persisting block rdd_32_3 to disk instead.\n",
      "23/04/13 17:40:54 WARN MemoryStore: Not enough space to cache rdd_32_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/13 17:40:55 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 13.0 MiB so far)\n",
      "23/04/13 17:40:56 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 3.4 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(title='Shawshank Redemption, The (1994)', Num_ratings=97999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated = X.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False)\n",
    "df_updated.limit(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the top N movies with the most reviews (ratings)\n",
    "\n",
    "\"\"\"\n",
    "# (may be necessary for @param type)\n",
    "import pyspark\n",
    "\n",
    "# 3. Most-rated movies\n",
    "def most_rated(df: pyspark.sql.dataframe.DataFrame, N=10):\n",
    "    if N == None:\n",
    "        return df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False)\n",
    "    else:\n",
    "        return df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False).limit(N)\n",
    "\n",
    "# Function that does everything; can be used for timing or outputting or whatever\n",
    "def most_rated_complete(N=10):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = most_rated(JOINED, N)\n",
    "    return TOP_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|Num_ratings|\n",
      "+--------------------+-----------+\n",
      "|Shawshank Redempt...|      97999|\n",
      "| Forrest Gump (1994)|      97040|\n",
      "| Pulp Fiction (1994)|      92406|\n",
      "|Silence of the La...|      87899|\n",
      "|  Matrix, The (1999)|      84545|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_rated(X, 5).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId', 'title', 'genres', 'userId', 'rating', 'timestamp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_rated_df = most_rated(X, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 18:09:18 WARN MemoryStore: Not enough space to cache rdd_35_4 in memory! (computed 22.6 MiB so far)\n",
      "23/04/18 18:09:18 WARN MemoryStore: Not enough space to cache rdd_35_3 in memory! (computed 22.6 MiB so far)\n",
      "23/04/18 18:09:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/04/18 18:09:18 WARN MemoryStore: Not enough space to cache rdd_35_2 in memory! (computed 22.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_rated_df.repartition(1).write.csv('results/500_most_rated.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the top N movies with the highest average reviews (ratings)\n",
    "\n",
    "\"\"\"\n",
    "# (may be necessary for @param type)\n",
    "import pyspark\n",
    "\n",
    "# 4. Highest-average-rated movies\n",
    "def best_average_rated(df: pyspark.sql.dataframe.DataFrame, N=10, MIN_RATINGS=50):\n",
    "    T = df.groupby(\"title\").agg(F.mean(\"rating\"))\n",
    "    H = T.withColumnRenamed(\"avg(rating)\", \"Mean_rating\")\n",
    "    # H.show(5)\n",
    "    G = df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\")\n",
    "    C = H.join(G, \"title\")\n",
    "    C = C.filter(C.Num_ratings >= MIN_RATINGS).select([\"title\", \"Mean_rating\"])\n",
    "    J = C.sort(\"Mean_rating\", ascending=False)\n",
    "    K = J.limit(N).withColumn(\"Mean_rating\", F.round(\"Mean_rating\",3))\n",
    "    return K\n",
    "\n",
    "# Function that does everything; can be used for timing or outputting or whatever\n",
    "def best_average_rated_complete(N=10, MIN_RATINGS=50):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = best_average_rated(JOINED, N, MIN_RATINGS)\n",
    "    return TOP_N #.select(\"*\", round(\"Mean_ratings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:07 WARN Utils: Your hostname, Coopers-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.16.108.70 instead (on interface en0)\n",
      "23/04/14 16:21:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/14 16:21:16 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:18 WARN BlockManager: Block rdd_23_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                  (0 + 8) / 8][Stage 5:>                  (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 54.3 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_1 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_2 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_0 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_4 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_3 to disk instead.\n",
      "23/04/14 16:21:46 WARN MemoryStore: Not enough space to cache rdd_37_6 in memory! (computed 54.7 MiB so far)\n",
      "23/04/14 16:21:46 WARN BlockManager: Persisting block rdd_37_6 to disk instead.\n",
      "23/04/14 16:21:46 WARN MemoryStore: Not enough space to cache rdd_37_5 in memory! (computed 54.7 MiB so far)\n",
      "23/04/14 16:21:46 WARN BlockManager: Persisting block rdd_37_5 to disk instead.\n",
      "23/04/14 16:21:46 WARN MemoryStore: Not enough space to cache rdd_37_7 in memory! (computed 54.6 MiB so far)\n",
      "23/04/14 16:21:46 WARN BlockManager: Persisting block rdd_37_7 to disk instead.\n",
      "23/04/14 16:21:52 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 12.9 MiB so far)\n",
      "23/04/14 16:21:52 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:53 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_37_0 in memory.\n",
      "23/04/14 16:21:53 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 384.0 B so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==>                (1 + 7) / 8][Stage 5:>                  (0 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:56 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 13.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===========>       (5 + 3) / 8][Stage 5:>                  (0 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:57 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 54.3 MiB so far)\n",
      "23/04/14 16:21:57 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 54.4 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:================>  (7 + 1) / 8][Stage 5:>                  (0 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:59 WARN MemoryStore: Not enough space to cache rdd_37_7 in memory! (computed 22.6 MiB so far)\n",
      "23/04/14 16:21:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/04/14 16:21:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|Mean_rating|\n",
      "+--------------------+-----------+\n",
      "|Planet Earth II (...|      4.487|\n",
      "| Planet Earth (2006)|      4.458|\n",
      "|Shawshank Redempt...|      4.424|\n",
      "|Band of Brothers ...|        4.4|\n",
      "|Black Mirror: Whi...|      4.351|\n",
      "|              Cosmos|      4.344|\n",
      "|The Godfather Tri...|       4.34|\n",
      "|Godfather, The (1...|      4.333|\n",
      "|Usual Suspects, T...|      4.292|\n",
      "|        Black Mirror|      4.264|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "A = best_average_rated_complete()\n",
    "A.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Popular genres: Find the top N popular genres by calculating the average rating for each genre.\n",
    "\"\"\"\n",
    "import pyspark\n",
    "def popular_genres(df: pyspark.sql.dataframe.DataFrame, N=5, MIN_RATINGS=10):\n",
    "    L = df.groupby(\"genres\").agg(F.mean(\"rating\"))\n",
    "    L.show(5)\n",
    "    M = L.withColumnRenamed(\"avg(rating)\", \"Mean_rating\")\n",
    "    G = df.groupby(\"genres\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\")\n",
    "    M.show(5)\n",
    "    K = M.join(G, \"genres\")\n",
    "    P = K.filter(K.Num_ratings >= MIN_RATINGS).select([\"genres\", \"Mean_rating\"])\n",
    "    N = P.sort(\"Mean_rating\", ascending=False).limit(N).withColumn(\"Mean_rating\", F.round(\"Mean_rating\",3))\n",
    "    return N\n",
    "def popular_genres_complete(N=5, MIN_RATINGS=10):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = popular_genres(JOINED, N)\n",
    "    return TOP_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 18:02:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "23/04/16 18:02:52 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/16 18:02:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "23/04/16 18:02:53 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/16 18:02:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/16 18:02:53 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:02:53 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 35.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|              genres|       avg(rating)|\n",
      "+--------------------+------------------+\n",
      "|Comedy|Horror|Thr...| 3.288320727995902|\n",
      "|Adventure|Sci-Fi|...| 3.212121212121212|\n",
      "|Action|Adventure|...| 4.011721534573262|\n",
      "| Action|Drama|Horror|3.7695176529090006|\n",
      "|Action|Animation|...|  3.76522506619594|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/04/16 18:02:57 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:02:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/16 18:02:57 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 35.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|              genres|       Mean_rating|\n",
      "+--------------------+------------------+\n",
      "|Comedy|Horror|Thr...| 3.288320727995902|\n",
      "|Adventure|Sci-Fi|...| 3.212121212121212|\n",
      "|Action|Adventure|...| 4.011721534573262|\n",
      "| Action|Drama|Horror|3.7695176529090006|\n",
      "|Action|Animation|...|  3.76522506619594|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/04/16 18:03:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/16 18:03:02 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:03:02 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 35.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:===========>      (5 + 3) / 8][Stage 42:>                 (0 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 18:03:04 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:03:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 35.3 MiB so far)\n",
      "23/04/16 18:03:04 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 22.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              genres|Mean_rating|\n",
      "+--------------------+-----------+\n",
      "|Action|Adventure|...|      4.201|\n",
      "|Film-Noir|Romance...|      4.164|\n",
      "|Action|Crime|Dram...|      4.163|\n",
      "|Action|Adventure|...|      4.157|\n",
      "|Action|Crime|Dram...|      4.156|\n",
      "|Adventure|Animati...|      4.152|\n",
      "|Animation|Childre...|      4.145|\n",
      "|   Film-Noir|Mystery|      4.128|\n",
      "|Crime|Film-Noir|M...|      4.127|\n",
      "|Action|Adventure|...|       4.12|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = popular_genres_complete(10)\n",
    "W.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. Year-wise analysis: \n",
    "\n",
    "Extract the release year from the movie title and analyze the number of movies released and their average ratings per year.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# code needs some work filtering out bad years, works in general but some title must not end with the year in ( )\n",
    "def year_analysis(df: pyspark.sql.dataframe.DataFrame):\n",
    "    # add year column\n",
    "    J = df.withColumn(\"year\", F.col(\"title\").substr(F.length(\"title\")-4, F.length(\"title\")).substr(1,4)).select(\"movieID\", \"year\")\n",
    "    K = J.join(open_with_spark(\"data/ratings.csv\").select(\"movieID\", \"rating\"), \"movieID\")\n",
    "    #K.show(200)\n",
    "    # get average rating per year\n",
    "    #D = K.groupby(\"year\").agg(F.mean(\"rating\")).withColumnRenamed(\"avg(rating)\", \"Mean_rating\").sort(\"Mean_rating\", ascending = False)\n",
    "    K = K.groupby(\"year\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False)\n",
    "    return  K #K.join(D, \"year\")\n",
    "def year_analysis_complete():\n",
    "    X = open_with_spark()\n",
    "    Y = year_analysis(X)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/17 16:39:58 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/17 16:39:59 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/17 16:39:59 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 22.5 MiB so far)\n",
      "23/04/17 16:39:59 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/17 16:39:59 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 35.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|  year|Num_ratings|\n",
      "+------+-----------+\n",
      "|  1995|    1767979|\n",
      "|  1994|    1529657|\n",
      "|  1996|    1334834|\n",
      "|  1999|    1305889|\n",
      "|  2000|    1089609|\n",
      "|  1993|    1082362|\n",
      "|  1997|    1080028|\n",
      "|  1998|    1040732|\n",
      "|  2001|     983000|\n",
      "|  2002|     885726|\n",
      "|  2004|     849291|\n",
      "|  2003|     779270|\n",
      "|  2006|     617677|\n",
      "|  2007|     579220|\n",
      "|  2005|     570873|\n",
      "|  1992|     567142|\n",
      "|  1989|     558507|\n",
      "|  1990|     548939|\n",
      "|  2008|     547974|\n",
      "|  2009|     507131|\n",
      "|  1991|     486961|\n",
      "|  2010|     456500|\n",
      "|  1988|     428412|\n",
      "|  1987|     424588|\n",
      "|  1986|     422299|\n",
      "|  1984|     403551|\n",
      "|  2011|     372899|\n",
      "|  2012|     362019|\n",
      "|  2014|     356580|\n",
      "|  1985|     348500|\n",
      "|  2013|     336980|\n",
      "|  1982|     303667|\n",
      "|  2015|     278900|\n",
      "|  1980|     270448|\n",
      "|  1983|     245945|\n",
      "|  1981|     245589|\n",
      "|  1979|     220638|\n",
      "|  2016|     204613|\n",
      "|  1975|     182415|\n",
      "|  1977|     170660|\n",
      "|  1971|     153949|\n",
      "|  1978|     136967|\n",
      "|  1973|     132878|\n",
      "|  1974|     130366|\n",
      "|  1968|     125388|\n",
      "|  2017|     122004|\n",
      "|  1976|     121598|\n",
      "|  1972|     118265|\n",
      "|  1964|     108186|\n",
      "|  1967|      99821|\n",
      "|  1962|      86824|\n",
      "|  1963|      80458|\n",
      "|  1959|      80382|\n",
      "|  1954|      79788|\n",
      "|  1960|      76628|\n",
      "|  1957|      69140|\n",
      "|  1961|      68828|\n",
      "|  1970|      67528|\n",
      "|  1939|      67043|\n",
      "|  1940|      66723|\n",
      "|  1969|      62521|\n",
      "|  1965|      60393|\n",
      "|  1941|      59875|\n",
      "|  1966|      55574|\n",
      "|  1955|      55313|\n",
      "|  1951|      55084|\n",
      "|  1958|      54603|\n",
      "|  1942|      53948|\n",
      "|  1953|      48457|\n",
      "|  1950|      47618|\n",
      "|  1946|      42872|\n",
      "|  1956|      39385|\n",
      "|  1937|      31128|\n",
      "|  1952|      30217|\n",
      "|  1944|      29174|\n",
      "|  1948|      26174|\n",
      "|  2018|      23329|\n",
      "|  1949|      21395|\n",
      "|  1931|      20997|\n",
      "|  1933|      19907|\n",
      "|  1938|      18922|\n",
      "|  1947|      16938|\n",
      "|  1935|      15292|\n",
      "|  1945|      14924|\n",
      "|  1934|      14394|\n",
      "|  1936|      12907|\n",
      "|  1932|       9612|\n",
      "|  1943|       9496|\n",
      "|  1927|       9120|\n",
      "|  1925|       7214|\n",
      "|  1930|       6175|\n",
      "|  1922|       5381|\n",
      "|  1928|       4352|\n",
      "|  1926|       3883|\n",
      "|  1929|       3136|\n",
      "|  1920|       2426|\n",
      "|  1921|       1962|\n",
      "|  1924|       1918|\n",
      "|  ligh|       1707|\n",
      "|  imal|       1341|\n",
      "|  1923|       1208|\n",
      "|  r On|       1105|\n",
      "|  1902|        731|\n",
      "|  1915|        593|\n",
      "|  1919|        544|\n",
      "|  012)|        528|\n",
      "|  1916|        523|\n",
      "|  erso|        458|\n",
      "|  011)|        441|\n",
      "|  998)|        394|\n",
      "|  013)|        336|\n",
      "|  1917|        305|\n",
      "|  1918|        301|\n",
      "|  010)|        300|\n",
      "|  008)|        233|\n",
      "|  1903|        222|\n",
      "|  he O|        213|\n",
      "|  lon |        200|\n",
      "|  007)|        195|\n",
      "|  002)|        192|\n",
      "|  014)|        187|\n",
      "|  1914|        186|\n",
      "|  irro|        180|\n",
      "|  995)|        164|\n",
      "|  osmo|        157|\n",
      "|  1896|        154|\n",
      "|  005)|        149|\n",
      "|  003)|        147|\n",
      "|  s wh|        129|\n",
      "|  999)|        118|\n",
      "|  atso|        113|\n",
      "|  986)|        107|\n",
      "|  1894|         95|\n",
      "|  1895|         88|\n",
      "|  1898|         81|\n",
      "|  astl|         73|\n",
      "|  1913|         70|\n",
      "|  006)|         69|\n",
      "|  009)|         68|\n",
      "|  1912|         63|\n",
      "|  1900|         62|\n",
      "|  1910|         56|\n",
      "|     u|         51|\n",
      "|  1908|         50|\n",
      "|  971)|         49|\n",
      "|  1901|         47|\n",
      "|  mina|         45|\n",
      "|  1897|         42|\n",
      "|  1911|         41|\n",
      "|  015)|         40|\n",
      "|   Roa|         38|\n",
      "|   Hel|         37|\n",
      "|  isse|         37|\n",
      "|  1909|         36|\n",
      "|  oys |         36|\n",
      "|  1906|         35|\n",
      "|  rrot|         34|\n",
      "|  017)|         32|\n",
      "|  988)|         32|\n",
      "|  Chil|         31|\n",
      "|  989)|         30|\n",
      "|  1888|         29|\n",
      "|  1891|         29|\n",
      "|  1904|         29|\n",
      "|  980)|         28|\n",
      "|  004)|         26|\n",
      "|  1907|         26|\n",
      "|  adge|         25|\n",
      "|  965)|         25|\n",
      "|   Kid|         22|\n",
      "|  1899|         22|\n",
      "|  1905|         22|\n",
      "|  997)|         21|\n",
      "|  Word|         21|\n",
      "|  1890|         21|\n",
      "|  erma|         20|\n",
      "|   Bab|         20|\n",
      "|  ture|         19|\n",
      "|  Worl|         18|\n",
      "|  001)|         17|\n",
      "|  Land|         16|\n",
      "|  983)|         16|\n",
      "|  nger|         16|\n",
      "|  Skie|         16|\n",
      "|  Viva|         15|\n",
      "|  970)|         15|\n",
      "|  984)|         14|\n",
      "|  1878|         14|\n",
      "|  1892|         13|\n",
      "|  roin|         13|\n",
      "|  993)|         13|\n",
      "|   Cag|         12|\n",
      "|  973)|         12|\n",
      "|   Cod|         12|\n",
      "|  976)|         12|\n",
      "|  lcon|         12|\n",
      "|  1893|         11|\n",
      "|  easo|         11|\n",
      "|  espo|         10|\n",
      "|  DGAM|         10|\n",
      "|  909)|         10|\n",
      "|  Stat|         10|\n",
      "|  1874|         10|\n",
      "|  958)|         10|\n",
      "|  azon|         10|\n",
      "|  990)|         10|\n",
      "|  950)|          9|\n",
      "|  1887|          9|\n",
      "|  piel|          9|\n",
      "|  egin|          9|\n",
      "|  938)|          9|\n",
      "|  948)|          8|\n",
      "|  umbe|          8|\n",
      "|  949)|          8|\n",
      "|  968)|          8|\n",
      "|  auru|          8|\n",
      "|  n Ma|          7|\n",
      "|  Sieg|          7|\n",
      "|  llin|          7|\n",
      "|   Gam|          6|\n",
      "|  Chas|          6|\n",
      "|  Cial|          6|\n",
      "|   Sha|          6|\n",
      "|  Stor|          6|\n",
      "|  Movi|          6|\n",
      "|  σάνη|          6|\n",
      "|  929)|          6|\n",
      "|  osro|          6|\n",
      "|  erco|          5|\n",
      "|  Aler|          5|\n",
      "|  ipse|          5|\n",
      "|  1883|          5|\n",
      "|  rint|          5|\n",
      "|  wing|          5|\n",
      "|  t Vo|          5|\n",
      "|  ron |          5|\n",
      "|  961)|          5|\n",
      "|  967)|          5|\n",
      "|  937)|          5|\n",
      "|  e Su|          5|\n",
      "|  ctio|          4|\n",
      "|  Powe|          4|\n",
      "|  Thre|          4|\n",
      "|  льни|          4|\n",
      "|   Fil|          4|\n",
      "|   sai|          4|\n",
      "|  undr|          4|\n",
      "|  ccen|          4|\n",
      "|  963)|          4|\n",
      "|   Kiy|          4|\n",
      "|  Smok|          4|\n",
      "|   Fir|          3|\n",
      "|  898)|          3|\n",
      "|  hang|          3|\n",
      "|   201|          3|\n",
      "|  Ange|          3|\n",
      "|  zode|          3|\n",
      "|  urit|          3|\n",
      "|  bore|          3|\n",
      "|  obot|          3|\n",
      "|  985)|          3|\n",
      "|  Ston|          3|\n",
      "|  maBo|          3|\n",
      "|  inso|          3|\n",
      "|  928)|          3|\n",
      "|  harm|          3|\n",
      "|  Star|          3|\n",
      "|  s/Al|          3|\n",
      "|  dium|          3|\n",
      "|  poma|          3|\n",
      "|  d Si|          3|\n",
      "|  ehin|          3|\n",
      "|  987)|          3|\n",
      "|   Ede|          3|\n",
      "|  igge|          3|\n",
      "|  pait|          3|\n",
      "|  mpic|          2|\n",
      "|   Lan|          2|\n",
      "|  Ital|          2|\n",
      "|  unis|          2|\n",
      "|  tori|          2|\n",
      "|  957)|          2|\n",
      "|   Gol|          2|\n",
      "|  irdi|          2|\n",
      "|   Hig|          2|\n",
      "|  inas|          2|\n",
      "|  Brea|          2|\n",
      "|  oman|          2|\n",
      "|  Gues|          2|\n",
      "|   Kin|          2|\n",
      "|  978)|          2|\n",
      "|  ntin|          2|\n",
      "|  isek|          2|\n",
      "|  ueño|          2|\n",
      "|  tree|          2|\n",
      "|  Hoon|          2|\n",
      "|  Zero|          2|\n",
      "|  ef m|          2|\n",
      "|  r Do|          2|\n",
      "|  rang|          2|\n",
      "|  g Re|          2|\n",
      "|  itio|          2|\n",
      "|  Eliá|          2|\n",
      "|  schk|          2|\n",
      "|  م پد|          2|\n",
      "|  astr|          2|\n",
      "|  embe|          2|\n",
      "|  Pran|          2|\n",
      "|  ille|          2|\n",
      "|  akhn|          2|\n",
      "|  gówn|          2|\n",
      "|  vers|          2|\n",
      "|  llär|          2|\n",
      "|  Grac|          2|\n",
      "|  977)|          2|\n",
      "|  utto|          2|\n",
      "|  stai|          2|\n",
      "|  ramb|          2|\n",
      "|  lfre|          2|\n",
      "|  rher|          2|\n",
      "|  urus|          2|\n",
      "|   Jee|          2|\n",
      "|  Apre|          2|\n",
      "|01次求|          2|\n",
      "|  ines|          1|\n",
      "|  eopl|          1|\n",
      "|  Firs|          1|\n",
      "|  k Ça|          1|\n",
      "|  nera|          1|\n",
      "|  ll D|          1|\n",
      "|  Wall|          1|\n",
      "|  975)|          1|\n",
      "|  t Ma|          1|\n",
      "|  hana|          1|\n",
      "|  asje|          1|\n",
      "|  Reha|          1|\n",
      "|   Hom|          1|\n",
      "|  994)|          1|\n",
      "|  roma|          1|\n",
      "|  ubdu|          1|\n",
      "|  ysse|          1|\n",
      "|  ort |          1|\n",
      "|  ke M|          1|\n",
      "|  erda|          1|\n",
      "|  pido|          1|\n",
      "|  arde|          1|\n",
      "|  ittl|          1|\n",
      "|  Brok|          1|\n",
      "|  956)|          1|\n",
      "|  kmat|          1|\n",
      "|   Hil|          1|\n",
      "|  ante|          1|\n",
      "|  trof|          1|\n",
      "|  aieh|          1|\n",
      "|  broa|          1|\n",
      "|  stic|          1|\n",
      "|  rcit|          1|\n",
      "|  tefa|          1|\n",
      "|  utur|          1|\n",
      "|  tnes|          1|\n",
      "|  blic|          1|\n",
      "|  unoo|          1|\n",
      "|  rabl|          1|\n",
      "|  Sara|          1|\n",
      "|   End|          1|\n",
      "|  e Gu|          1|\n",
      "|  972)|          1|\n",
      "|  Nigh|          1|\n",
      "|  Mara|          1|\n",
      "|  Bega|          1|\n",
      "|  Tohn|          1|\n",
      "|  Hont|          1|\n",
      "|   Onl|          1|\n",
      "|  Fant|          1|\n",
      "|   Okn|          1|\n",
      "|  Bloo|          1|\n",
      "|  Chao|          1|\n",
      "|  sell|          1|\n",
      "|  omin|          1|\n",
      "|  avou|          1|\n",
      "|  at 2|          1|\n",
      "|  o Cã|          1|\n",
      "|   min|          1|\n",
      "|  ijda|          1|\n",
      "|  Lich|          1|\n",
      "|  Mhan|          1|\n",
      "|  -Hun|          1|\n",
      "|   Ala|          1|\n",
      "|   nam|          1|\n",
      "|  rize|          1|\n",
      "|  Hole|          1|\n",
      "|   svě|          1|\n",
      "|  Blue|          1|\n",
      "|  09– |          1|\n",
      "|  kles|          1|\n",
      "|  tanc|          1|\n",
      "|  Mone|          1|\n",
      "|  roun|          1|\n",
      "|  Mora|          1|\n",
      "|   Mov|          1|\n",
      "|  íjás|          1|\n",
      "|  Trus|          1|\n",
      "|  tuar|          1|\n",
      "|  ghte|          1|\n",
      "|   Dog|          1|\n",
      "|  ions|          1|\n",
      "|   Edg|          1|\n",
      "|  arit|          1|\n",
      "|  eedo|          1|\n",
      "|  Mari|          1|\n",
      "|  legu|          1|\n",
      "|  łośc|          1|\n",
      "|  rder|          1|\n",
      "|  rves|          1|\n",
      "|  etan|          1|\n",
      "|  wRin|          1|\n",
      "|  runk|          1|\n",
      "|   Sho|          1|\n",
      "|  förs|          1|\n",
      "|  Indi|          1|\n",
      "|  ebaa|          1|\n",
      "|  Jatr|          1|\n",
      "|  hter|          1|\n",
      "|  Teru|          1|\n",
      "|  elje|          1|\n",
      "|  inte|          1|\n",
      "|  itua|          1|\n",
      "|  horn|          1|\n",
      "|   Tre|          1|\n",
      "|  ckof|          1|\n",
      "|  thfu|          1|\n",
      "|   lov|          1|\n",
      "|  вани|          1|\n",
      "|   Yor|          1|\n",
      "|   Nyr|          1|\n",
      "|  Mill|          1|\n",
      "|  eser|          1|\n",
      "|  llar|          1|\n",
      "|  rlyl|          1|\n",
      "|  ihar|          1|\n",
      "|   Rid|          1|\n",
      "|  dvic|          1|\n",
      "|    6A|          1|\n",
      "|   Sno|          1|\n",
      "|  alay|          1|\n",
      "|  d Su|          1|\n",
      "|  inde|          1|\n",
      "|  egas|          1|\n",
      "|   Kar|          1|\n",
      "|  soni|          1|\n",
      "|  e Fo|          1|\n",
      "|  ight|          1|\n",
      "|   Fal|          1|\n",
      "|  Kade|          1|\n",
      "|  Sinc|          1|\n",
      "|  esap|          1|\n",
      "|  Mort|          1|\n",
      "+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "A = year_analysis_complete()\n",
    "A.show(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af4521a1c734e7c65889f479bb79ece66303508270e0aa19c37418c08bff644d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
