{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "#PYSPARK_DRIVER_PYTHON = 3.85\n",
    "#PYSPARK_PYTHON = 3.85\n",
    "import os\n",
    "import sys\n",
    "#import pyspark as spark\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Same code as shown in SimpleApp.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_with_spark(log_file=\"data/movies.csv\", app_name=\"movieAnalysis\"):\n",
    "    spark = SparkSession.builder.appName(app_name).getOrCreate()\n",
    "    df = spark.read.option(\"header\",True).csv(log_file).cache()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\"\"\"\n",
    "1. Summary statistics for each relevant data frame\n",
    "\n",
    "\"\"\"\n",
    "def summary_statistics(df: pyspark.sql.dataframe.DataFrame, cols= [\"*\"], stats = [\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"75%\", \"max\"]):\n",
    "    df.select(*cols).summary(*stats).show()\n",
    "# Do all\n",
    "def summary_statistics_complete(file= \"data/ratings.csv\", cols= [\"*\"], stats = [\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"75%\", \"max\"]):\n",
    "    summary_statistics(open_with_spark(file), cols, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 15:54:57 WARN CacheManager: Asked to cache already cached data.\n",
      "+-------+-----+\n",
      "|summary|title|\n",
      "+-------+-----+\n",
      "|  count|58098|\n",
      "+-------+-----+\n",
      "\n",
      "23/04/16 15:54:58 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/16 15:54:58 WARN MemoryStore: Not enough space to cache rdd_55_1 in memory! (computed 6.6 MiB so far)\n",
      "23/04/16 15:54:58 WARN MemoryStore: Not enough space to cache rdd_55_0 in memory! (computed 6.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|summary|userID|\n",
      "+-------+------+\n",
      "|  count|283228|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Print out number of movies and number of unqiue users.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "summary_statistics_complete(\"data/movies.csv\",[\"title\"], [\"count\"])\n",
    "# Get df of unique users\n",
    "df_unique_users = open_with_spark(\"data/ratings.csv\").select(\"UserID\").distinct()\n",
    "summary_statistics(df_unique_users,[\"userID\"], [\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 15:51:00 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/16 15:51:01 WARN MemoryStore: Not enough space to cache rdd_55_0 in memory! (computed 13.0 MiB so far)\n",
      "23/04/16 15:51:01 WARN MemoryStore: Not enough space to cache rdd_55_1 in memory! (computed 12.9 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          27753444|\n",
      "|   mean|3.5304452124932677|\n",
      "| stddev| 1.066352750231989|\n",
      "|    min|               0.5|\n",
      "|    25%|               3.0|\n",
      "|    75%|               4.0|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "summary_statistics_complete(\"data/ratings.csv\",[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Join Dataframes READABLE version, more memory needed\n",
    "def join_ratings_and_movies_readable():  \n",
    "    df_movie = open_with_spark()\n",
    "    df_ratings = open_with_spark(log_file=\"data/ratings.csv\", app_name=\"ratings\")\n",
    "    df_join = df_ratings.join(df_movie, \"movieID\")\n",
    "    return df_join\n",
    "    \n",
    "# 2. Join Dataframes\n",
    "def join_ratings_and_movies(): \n",
    "    return open_with_spark().join(open_with_spark(log_file=\"data/ratings.csv\", app_name=\"ratings\"), \"movieID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 12:18:58 WARN Utils: Your hostname, Coopers-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.16.108.70 instead (on interface en0)\n",
      "23/04/14 12:18:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 12:18:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/14 12:19:06 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+------+------+----------+\n",
      "|movieId|               title|        genres|userId|rating| timestamp|\n",
      "+-------+--------------------+--------------+------+------+----------+\n",
      "|    307|Three Colors: Blu...|         Drama|     1|   3.5|1256677221|\n",
      "|    481|   Kalifornia (1993)|Drama|Thriller|     1|   3.5|1256677456|\n",
      "|   1091|Weekend at Bernie...|        Comedy|     1|   1.5|1256677471|\n",
      "|   1257|Better Off Dead.....|Comedy|Romance|     1|   4.5|1256677460|\n",
      "|   1449|Waiting for Guffm...|        Comedy|     1|   4.5|1256677264|\n",
      "+-------+--------------------+--------------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X = join_ratings_and_movies()\n",
    "X.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/13 17:40:44 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 35.3 MiB so far)\n",
      "23/04/13 17:40:44 WARN BlockManager: Persisting block rdd_32_1 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_7 in memory! (computed 54.6 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_7 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_2 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_6 in memory! (computed 54.7 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_6 to disk instead.\n",
      "23/04/13 17:40:50 WARN MemoryStore: Not enough space to cache rdd_32_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/13 17:40:50 WARN BlockManager: Persisting block rdd_32_4 to disk instead.\n",
      "23/04/13 17:40:51 WARN MemoryStore: Not enough space to cache rdd_32_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/13 17:40:51 WARN BlockManager: Persisting block rdd_32_3 to disk instead.\n",
      "23/04/13 17:40:54 WARN MemoryStore: Not enough space to cache rdd_32_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/13 17:40:55 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 13.0 MiB so far)\n",
      "23/04/13 17:40:56 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 3.4 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(title='Shawshank Redemption, The (1994)', Num_ratings=97999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated = X.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False)\n",
    "df_updated.limit(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the top N movies with the most reviews (ratings)\n",
    "\n",
    "\"\"\"\n",
    "# (may be necessary for @param type)\n",
    "import pyspark\n",
    "\n",
    "# 3. Most-rated movies\n",
    "def most_rated(df: pyspark.sql.dataframe.DataFrame, N=10):\n",
    "    return df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\").sort(\"Num_ratings\", ascending=False).limit(N)\n",
    "\n",
    "# Function that does everything; can be used for timing or outputting or whatever\n",
    "def most_rated_complete(N=10):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = most_rated(JOINED, N)\n",
    "    return TOP_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 17:13:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/16 17:13:59 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_5 in memory! (computed 54.7 MiB so far)\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_5 to disk instead.\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_2 to disk instead.\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 54.3 MiB so far)\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_7 in memory! (computed 54.6 MiB so far)\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_7 to disk instead.\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_1 to disk instead.\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 54.4 MiB so far)\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_0 to disk instead.\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_6 in memory! (computed 54.7 MiB so far)\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_4 to disk instead.\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_6 to disk instead.\n",
      "23/04/16 17:14:22 WARN MemoryStore: Not enough space to cache rdd_32_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/16 17:14:22 WARN BlockManager: Persisting block rdd_32_3 to disk instead.\n",
      "23/04/16 17:14:27 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/16 17:14:27 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 12.9 MiB so far)\n",
      "23/04/16 17:14:27 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_32_0 in memory.\n",
      "23/04/16 17:14:27 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 384.0 B so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|Num_ratings|\n",
      "+--------------------+-----------+\n",
      "|Shawshank Redempt...|      97999|\n",
      "| Forrest Gump (1994)|      97040|\n",
      "| Pulp Fiction (1994)|      92406|\n",
      "|Silence of the La...|      87899|\n",
      "|  Matrix, The (1999)|      84545|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_rated_complete(5).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the top N movies with the highest average reviews (ratings)\n",
    "\n",
    "\"\"\"\n",
    "# (may be necessary for @param type)\n",
    "import pyspark\n",
    "\n",
    "# 4. Highest-average-rated movies\n",
    "def best_average_rated(df: pyspark.sql.dataframe.DataFrame, N=10, MIN_RATINGS=50):\n",
    "    T = df.groupby(\"title\").agg(F.mean(\"rating\"))\n",
    "    H = T.withColumnRenamed(\"avg(rating)\", \"Mean_rating\")\n",
    "    # H.show(5)\n",
    "    G = df.groupby(\"title\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\")\n",
    "    C = H.join(G, \"title\")\n",
    "    C = C.filter(C.Num_ratings >= MIN_RATINGS).select([\"title\", \"Mean_rating\"])\n",
    "    J = C.sort(\"Mean_rating\", ascending=False)\n",
    "    K = J.limit(N).withColumn(\"Mean_rating\", F.round(\"Mean_rating\",3))\n",
    "    return K\n",
    "\n",
    "# Function that does everything; can be used for timing or outputting or whatever\n",
    "def best_average_rated_complete(N=10, MIN_RATINGS=50):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = best_average_rated(JOINED, N, MIN_RATINGS)\n",
    "    return TOP_N #.select(\"*\", round(\"Mean_ratings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:07 WARN Utils: Your hostname, Coopers-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.16.108.70 instead (on interface en0)\n",
      "23/04/14 16:21:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/14 16:21:16 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:18 WARN BlockManager: Block rdd_23_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                  (0 + 8) / 8][Stage 5:>                  (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 54.3 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_1 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_2 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_0 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_4 in memory! (computed 54.6 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_4 to disk instead.\n",
      "23/04/14 16:21:45 WARN MemoryStore: Not enough space to cache rdd_37_3 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:45 WARN BlockManager: Persisting block rdd_37_3 to disk instead.\n",
      "23/04/14 16:21:46 WARN MemoryStore: Not enough space to cache rdd_37_6 in memory! (computed 54.7 MiB so far)\n",
      "23/04/14 16:21:46 WARN BlockManager: Persisting block rdd_37_6 to disk instead.\n",
      "23/04/14 16:21:46 WARN MemoryStore: Not enough space to cache rdd_37_5 in memory! (computed 54.7 MiB so far)\n",
      "23/04/14 16:21:46 WARN BlockManager: Persisting block rdd_37_5 to disk instead.\n",
      "23/04/14 16:21:46 WARN MemoryStore: Not enough space to cache rdd_37_7 in memory! (computed 54.6 MiB so far)\n",
      "23/04/14 16:21:46 WARN BlockManager: Persisting block rdd_37_7 to disk instead.\n",
      "23/04/14 16:21:52 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 12.9 MiB so far)\n",
      "23/04/14 16:21:52 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 54.4 MiB so far)\n",
      "23/04/14 16:21:53 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_37_0 in memory.\n",
      "23/04/14 16:21:53 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 384.0 B so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==>                (1 + 7) / 8][Stage 5:>                  (0 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:56 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 13.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===========>       (5 + 3) / 8][Stage 5:>                  (0 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:57 WARN MemoryStore: Not enough space to cache rdd_37_1 in memory! (computed 54.3 MiB so far)\n",
      "23/04/14 16:21:57 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 54.4 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:================>  (7 + 1) / 8][Stage 5:>                  (0 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 16:21:59 WARN MemoryStore: Not enough space to cache rdd_37_7 in memory! (computed 22.6 MiB so far)\n",
      "23/04/14 16:21:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/04/14 16:21:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|Mean_rating|\n",
      "+--------------------+-----------+\n",
      "|Planet Earth II (...|      4.487|\n",
      "| Planet Earth (2006)|      4.458|\n",
      "|Shawshank Redempt...|      4.424|\n",
      "|Band of Brothers ...|        4.4|\n",
      "|Black Mirror: Whi...|      4.351|\n",
      "|              Cosmos|      4.344|\n",
      "|The Godfather Tri...|       4.34|\n",
      "|Godfather, The (1...|      4.333|\n",
      "|Usual Suspects, T...|      4.292|\n",
      "|        Black Mirror|      4.264|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "A = best_average_rated_complete()\n",
    "A.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Popular genres: Find the top N popular genres by calculating the average rating for each genre.\n",
    "\"\"\"\n",
    "import pyspark\n",
    "def popular_genres(df: pyspark.sql.dataframe.DataFrame, N=5, MIN_RATINGS=10):\n",
    "    L = df.groupby(\"genres\").agg(F.mean(\"rating\"))\n",
    "    L.show(5)\n",
    "    M = L.withColumnRenamed(\"avg(rating)\", \"Mean_rating\")\n",
    "    G = df.groupby(\"genres\").agg(F.count(\"rating\")).withColumnRenamed(\"count(rating)\", \"Num_ratings\")\n",
    "    M.show(5)\n",
    "    K = M.join(G, \"genres\")\n",
    "    P = K.filter(K.Num_ratings >= MIN_RATINGS).select([\"genres\", \"Mean_rating\"])\n",
    "    N = P.sort(\"Mean_rating\", ascending=False).limit(N).withColumn(\"Mean_rating\", F.round(\"Mean_rating\",3))\n",
    "    return N\n",
    "def popular_genres_complete(N=5, MIN_RATINGS=10):\n",
    "    JOINED = join_ratings_and_movies()\n",
    "    TOP_N = popular_genres(JOINED, N)\n",
    "    return TOP_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 18:02:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "23/04/16 18:02:52 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/16 18:02:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "23/04/16 18:02:53 WARN CacheManager: Asked to cache already cached data.\n",
      "23/04/16 18:02:53 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/16 18:02:53 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:02:53 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 35.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|              genres|       avg(rating)|\n",
      "+--------------------+------------------+\n",
      "|Comedy|Horror|Thr...| 3.288320727995902|\n",
      "|Adventure|Sci-Fi|...| 3.212121212121212|\n",
      "|Action|Adventure|...| 4.011721534573262|\n",
      "| Action|Drama|Horror|3.7695176529090006|\n",
      "|Action|Animation|...|  3.76522506619594|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/04/16 18:02:57 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:02:57 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/16 18:02:57 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 35.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|              genres|       Mean_rating|\n",
      "+--------------------+------------------+\n",
      "|Comedy|Horror|Thr...| 3.288320727995902|\n",
      "|Adventure|Sci-Fi|...| 3.212121212121212|\n",
      "|Action|Adventure|...| 4.011721534573262|\n",
      "| Action|Drama|Horror|3.7695176529090006|\n",
      "|Action|Animation|...|  3.76522506619594|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "23/04/16 18:03:02 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 22.6 MiB so far)\n",
      "23/04/16 18:03:02 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:03:02 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 35.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:===========>      (5 + 3) / 8][Stage 42:>                 (0 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/16 18:03:04 WARN MemoryStore: Not enough space to cache rdd_32_1 in memory! (computed 22.5 MiB so far)\n",
      "23/04/16 18:03:04 WARN MemoryStore: Not enough space to cache rdd_32_0 in memory! (computed 35.3 MiB so far)\n",
      "23/04/16 18:03:04 WARN MemoryStore: Not enough space to cache rdd_32_2 in memory! (computed 22.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              genres|Mean_rating|\n",
      "+--------------------+-----------+\n",
      "|Action|Adventure|...|      4.201|\n",
      "|Film-Noir|Romance...|      4.164|\n",
      "|Action|Crime|Dram...|      4.163|\n",
      "|Action|Adventure|...|      4.157|\n",
      "|Action|Crime|Dram...|      4.156|\n",
      "|Adventure|Animati...|      4.152|\n",
      "|Animation|Childre...|      4.145|\n",
      "|   Film-Noir|Mystery|      4.128|\n",
      "|Crime|Film-Noir|M...|      4.127|\n",
      "|Action|Adventure|...|       4.12|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = popular_genres_complete(10)\n",
    "W.show(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af4521a1c734e7c65889f479bb79ece66303508270e0aa19c37418c08bff644d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
